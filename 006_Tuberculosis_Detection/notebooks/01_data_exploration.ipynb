{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# os: A built-in Python library for interacting with the operating system. \n",
    "# We'll use it to work with file paths.\n",
    "import os\n",
    "\n",
    "# numpy: A fundamental package for numerical computation in Python.\n",
    "# It provides support for large, multi-dimensional arrays and matrices, \n",
    "# along with a large collection of high-level mathematical functions to operate on these arrays.\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib.pyplot: A plotting library for the Python programming language and its numerical mathematics extension NumPy.\n",
    "# We'll use it to visualize our images and plot graphs of our training and validation metrics.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pandas: A fast, powerful, flexible and easy to use open source data analysis and manipulation tool.\n",
    "# While we might not use it heavily for image data, it's a good practice to have it ready for any tabular data we might encounter.\n",
    "import pandas as pd\n",
    "\n",
    "# tensorflow: An end-to-end open source platform for machine learning.\n",
    "# It has a comprehensive, flexible ecosystem of tools, libraries and community resources that lets researchers push the state-of-the-art in ML \n",
    "# and developers easily build and deploy ML powered applications.\n",
    "import tensorflow as tf\n",
    "\n",
    "# ImageDataGenerator: A class from the Keras library (which is part of TensorFlow) that allows to build Python generators for image data.\n",
    "# These generators can be used to automatically load, preprocess, and augment images in real-time during model training.\n",
    "# This is a very memory-efficient way to work with large datasets.\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to your training and testing directories.\n",
    "# It's a good practice to define these as variables at the top of your script,\n",
    "# so you can easily change them if you move your data around.\n",
    "train_dir = '../data/chestxrays/train'\n",
    "test_dir = '../data/chestxrays/test'\n",
    "\n",
    "# Get the number of images in the training and validation directories\n",
    "num_train = sum([len(files) for r, d, files in os.walk(train_dir)])\n",
    "num_val = sum([len(files) for r, d, files in os.walk(test_dir)])\n",
    "\n",
    "# Define some parameters\n",
    "batch_size = 20\n",
    "epochs = 30\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150\n",
    "\n",
    "# Create an ImageDataGenerator for the training set.\n",
    "# This will be used to generate batches of tensor image data with real-time data augmentation.\n",
    "# The data will be looped over (in batches).\n",
    "train_datagen = ImageDataGenerator(\n",
    "    # Rescale the pixel values from [0, 255] to [0, 1]. \n",
    "    # Neural networks generally work better with small input values.\n",
    "    rescale=1./255,\n",
    "    # The following are data augmentation parameters.\n",
    "    # Data augmentation is a technique to artificially increase the size of your training dataset\n",
    "    # by creating modified versions of the images in the dataset.\n",
    "    # This helps to prevent overfitting and makes the model more robust.\n",
    "\n",
    "    # rotation_range is a value in degrees (0-180), a range within which to randomly rotate pictures.\n",
    "    rotation_range=20,\n",
    "    # width_shift_range and height_shift_range are ranges (as a fraction of total width or height) \n",
    "    # within which to randomly translate pictures vertically or horizontally.\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    # shear_range is for randomly applying shearing transformations.\n",
    "    shear_range=0.2,\n",
    "    # zoom_range is for randomly zooming inside pictures.\n",
    "    zoom_range=0.2,\n",
    "    # horizontal_flip is for randomly flipping half of the images horizontally. \n",
    "    # This is relevant for X-ray images as the left and right sides are generally symmetrical.\n",
    "    horizontal_flip=True,\n",
    "    # fill_mode is the strategy used for filling in newly created pixels, \n",
    "    # which can appear after a rotation or a width/height shift.\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Create an ImageDataGenerator for the test set.\n",
    "# For the test set, we only need to rescale the images. \n",
    "# We don't apply data augmentation to the test set because we want to evaluate the model on the original, unmodified images.\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create the data generators using the .flow_from_directory() method.\n",
    "# This method is very convenient as it allows you to read the images directly from the directories, \n",
    "# and it automatically labels the images based on the directory names.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, # The path to the training directory.\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),  # All images will be resized to 150x150.\n",
    "    # It's important to use a consistent image size for the model.\n",
    "    batch_size=batch_size, # The number of images to generate from the generator per batch.\n",
    "    class_mode='binary'  # Since we have two classes (healthy and tb), we use 'binary' class mode.\n",
    "    # This means the labels will be 0 or 1.\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir, # The path to the testing directory.\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH), # All images will be resized to 150x150.\n",
    "    batch_size=batch_size, # The number of images to generate from the generator per batch.\n",
    "    class_mode='binary' # Since we have two classes (healthy and tb), we use 'binary' class mode.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "\n",
    "# We will use the Keras Sequential API, which allows us to create models layer-by-layer.\n",
    "# This is a simple and intuitive way to build models.\n",
    "model = tf.keras.models.Sequential([\n",
    "    # The first layer is a convolutional layer. \n",
    "    # It has 32 filters of size 3x3. The activation function is 'relu' (Rectified Linear Unit), which is a common choice for CNNs.\n",
    "    # The input_shape is the size of our images (150x150) and the number of color channels (3 for RGB).\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    \n",
    "    # The next layer is a max pooling layer.\n",
    "    # It takes the maximum value from a 2x2 pool, which helps to reduce the spatial dimensions of the feature maps.\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    # We add another convolutional layer and a max pooling layer.\n",
    "    # It's common to stack multiple convolutional and pooling layers to allow the network to learn more complex features.\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    # Another convolutional and max pooling layer.\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    # Another convolutional and max pooling layer.\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    # Flatten the results to feed into a DNN\n",
    "    # This layer converts the 2D feature maps into a 1D vector.\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # A fully connected (Dense) layer with 512 neurons.\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    \n",
    "    # The output layer. It has a single neuron with a sigmoid activation function.\n",
    "    # The sigmoid function outputs a value between 0 and 1, which we can interpret as the probability of the image belonging to the 'tb' class.\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Print a summary of the model.\n",
    "# This is a good way to check the architecture of your model and the number of parameters.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "# Before we can train the model, we need to configure the learning process. \n",
    "# This is done using the compile() method.\n",
    "model.compile(\n",
    "    # The optimizer is the algorithm that will be used to update the weights of the model.\n",
    "    # We will use the Adam optimizer, which is a popular and effective choice for many deep learning models.\n",
    "    optimizer='adam',\n",
    "    # The loss function is what the model will try to minimize during training.\n",
    "    # For a binary classification problem like ours, 'binary_crossentropy' is the standard choice.\n",
    "    loss='binary_crossentropy',\n",
    "    # The metrics are used to monitor the training and testing steps.\n",
    "    # We will use 'accuracy' to measure the percentage of correctly classified images.\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "# We will now train the model using the fit() method.\n",
    "# This method will train the model for a fixed number of epochs (iterations on a dataset).\n",
    "history = model.fit(\n",
    "    # The training data generator.\n",
    "    train_generator,\n",
    "    # The number of steps to take in each epoch. \n",
    "    # This is usually the number of training samples divided by the batch size.\n",
    "    steps_per_epoch=num_train // batch_size,\n",
    "    # The number of epochs to train the model for.\n",
    "    epochs=epochs,\n",
    "    # The validation data generator.\n",
    "    validation_data=validation_generator,\n",
    "    # The number of steps to take in each validation epoch.\n",
    "    validation_steps=num_val // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy and loss\n",
    "\n",
    "# We can now plot the training and validation accuracy and loss to see how the model performed.\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "# It's a good practice to save your trained model so you can reuse it later without having to retrain it.\n",
    "# We will save the model in the HDF5 format, which is a common format for saving Keras models.\n",
    "model.save('tuberculosis_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}